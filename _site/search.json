[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1 - Programming Elegant DataVis with ggplot2",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched in R.\n\npacman::p_load(tidyverse)\n#package name with :: is used as the package has not been loaded in the r environment but you want to use the package functions for your project.\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2 - Creating Elegant Graphics with ggplot2",
    "section": "",
    "text": "Before we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\n\n\npacman::p_load(tidyverse, patchwork, ggthemes, ggrepel, hrbrthemes)\n\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data <- read_csv('data/Exam_data.csv')\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation",
    "title": "Hands-on Exercise 2 - Creating Elegant Graphics with ggplot2",
    "section": "Beyond ggplot2 Annotation",
    "text": "Beyond ggplot2 Annotation\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = 'lm', size = 0.5) +\n  geom_label(aes(label = ID), hjust = 0.5, vjust = -0.5) +\n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English Scores vs Maths Scores for Primary 3\")\n\n\n\n\n\nWorking with ggrepel\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text. We simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = 'lm', size = 0.5) +\n  geom_label_repel(aes(label = ID), hjust = 0.5, vjust = -0.5) +\n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English Scores vs Maths Scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2 - Creating Elegant Graphics with ggplot2",
    "section": "Beyond ggplot2 Themes",
    "text": "Beyond ggplot2 Themes\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Math Scores\")\n\n\n\n\n\nWorking with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") +\n  theme_economist() +\n  ggtitle(\"Distribution of Math Scores\")\n\n\n\n\n\n\nWorking with ggtheme package\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") +\n  theme_ipsum() +\n  ggtitle(\"Distribution of Math Scores\")\n\n\n\n\nWe use -\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\nggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") +\n  ggtitle(\"Distribution of Math Scores\") +\n  theme_ipsum(axis_title_size = 18, base_size = 15, grid = \"Y\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-facet",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-facet",
    "title": "Hands-on Exercise 2 - Creating Elegant Graphics with ggplot2",
    "section": "Beyond ggplot2 facet",
    "text": "Beyond ggplot2 facet\nIn this section, we learn how to create composite plot by combining multiple graphs. First, lets create three statistical graphics.\n\np1 <- ggplot(data = exam_data, aes(x = MATHS)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") + \n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 <- ggplot(data = exam_data, aes(x = ENGLISH)) +\n  geom_histogram(bins = 20, boundary = 100, color = \"grey25\", fill = \"grey90\") + \n  coord_cartesian(xlim = c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 <- ggplot(data = exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", size = 0.5) + \n  coord_cartesian(xlim = c(0,100), ylim = c(0,100)) +\n  ggtitle(\"English Scores vs Maths Scores for Primary 3\")\n\n\nCreating Composite Graphics: pathwork methods\nIt is not unusual that somtimes multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions that provide functions to compose figure with multiple graphs. In this section, we use patchwork. Patchwork package has a very simple syntax where we can create layouts easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign \\\n\n\np1 + p2 / p3\n\n\n\n\n| will place the plots beside each other, while / will stack them.\n\n(p1 / p2) | p3\n\n\n\n\npatchwork also provides auto-tagging capabilities, in order to identify subplots in text.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\nPlotting patchwork with ggtheme\n\npatchwork <- (p1 / p2) | p3\npatchwork & theme_economist()\n\n\n\n\nBesides providing functions to place plots next to each other based on the provided layout, with inset_element() of patchwork, we can place one or several plots and graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, left = 0.02, bottom = 0.7, right = 0.5, top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "pacman::p_load(dplyr, ggiraph, ggplot2, ggthemes, ggrepel, gganimate, patchwork, hrbrthemes, plotly, DT, RColorBrewer, gridExtra, extrafont, tidyverse, gifski, gapminder, readxl, rPackedBar)\n\n\n\n\nUsing read_csv() of readr package, we import Exam_data.csv into R.\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - ggiraph methods",
    "text": "Interactive Data Visualisation - ggiraph methods\n\nggiraph is an html widget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it is used within a Shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides.\n\n\nTooltip effect with tooltip aesthetic\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(tooltip = ID), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618)\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\nComparing ggplot2 and ggiraph codes\nThe original ggplot2 code chunk.\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5, dotsize = 0.5) +\n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\nThe ggiraph code chunk.\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(tooltip = ID), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618)\n\n\n\n\n\n\n\nDisplaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip <- c(paste0(\"Name = \", exam_data$ID, \"\\n Class = \", exam_data$CLASS))\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(tooltip = exam_data$tooltip), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 8, height_svg = 8*0.618)\n\n\n\n\n\n\n\nCustomising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css <- \"background-color:white; font-style:bold; color:black;\"\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618, options = list(opts_tooltip(css = tooltip_css))) \n\n\n\n\n\n\n\nDisplaying statistics on tooltip\nIn the below example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip <- function(y, ymax, accuracy = .01) \n  {\n  \n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n  \n  } \n\ngg_point <- ggplot(data=exam_data, aes(x = RACE)) +\n  \n  stat_summary(aes(y = MATHS, tooltip = after_stat(tooltip(y, ymax))), fun.data = \"mean_se\", geom = GeomInteractiveCol, fill = \"light blue\") +\n  \n  stat_summary(aes(y = MATHS), fun.data = mean_se, geom = \"errorbar\", width = 0.2, size = 0.2)\n\ngirafe(ggobj = gg_point, width_svg = 8, height_svg = 8*0.618)\n\n\n\n\n\n\n\nHover effect with data_id aesthetic\nCode chunk below show the second interactive feature of ggiraph, namely data_id.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(data_id = CLASS), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618)      \n\n\n\n\n\n\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(data_id = CLASS), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6,height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\")\n                )\n       )                                        \n\n\n\n\n\n\n\nCombining tooltip and hover effect\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(tooltip = CLASS, data_id = CLASS), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n) \n\n\n\n\n\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on ther web.\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(onclick = onclick), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618) \n\n\n\n\n\nNote: click actions must be a string column in the dataset containing valid javascript instructions.\n\n\nCoordinated Multiple Views with ggiraph\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 <- ggplot(data=exam_data, aes(x = MATHS)) +\n  \n  geom_dotplot_interactive(aes(data_id = ID), stackgroups = TRUE, binwidth = 1, method = \"histodot\") +  \n  \n  coord_cartesian(xlim=c(0,100)) +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\n\np2 <- ggplot(data=exam_data, aes(x = ENGLISH)) +\n  \n  geom_dotplot_interactive(aes(data_id = ID), stackgroups = TRUE, binwidth = 1, method = \"histodot\") + coord_cartesian(xlim=c(0,100)) +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(code = print(p1 / p2), width_svg = 6, height_svg = 6, options = list(opts_hover(css = \"fill: #202020;\"), opts_hover_inv(css = \"opacity:0.2;\"))) \n\n\n\n\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - plotly methods!",
    "text": "Interactive Data Visualisation - plotly methods!\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\nCreating an interactive scatter plot: plot_ly() method\nThe code chunk below plots an interactive scatter plot by using plot_ly().\n\nplot_ly(data = exam_data, x = ~MATHS, y = ~ENGLISH)\n\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\nInteractivity: Click on the colour symbol at the legend.\n\nplot_ly(data = exam_data, x = ~ENGLISH, y = ~MATHS, color = ~RACE)\n\n\n\n\n\n\n\nChanging colour pallete: plot_ly() method\nIn the code chunk below, colors argument is used to change the default colour palette to ColorBrewel colour palette.\nInteractivity: Click on the colour symbol at the legend.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = \"Set1\")\n\n\n\n\n\n\n\nCustomising colour scheme: plot_ly() method\nIn the code chunk below, a customised colour scheme is created. Then, colors argument is used to change the default colour palette to the customised colour scheme.\nInteractivity: Click on the colour symbol at the legend.\n\npal <- c(\"red\", \"purple\", \"blue\", \"green\")\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = pal)\n\n\n\n\n\n\n\nCustomising tooltip: plot_ly() method\nIn the code chunk below, text argument is used to change the default tooltip.\nInteractivity: Click on the colour symbol at the legend.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID, \"<br>Class:\", CLASS),\n        color = ~RACE, \n        colors = \"Set1\")\n\n\n\n\n\n\n\nWorking with layout: plot_ly() method\nIn the code chunk below, layout argument is used to change the default tooltip.\nInteractivity: Click on the colour symbol at the legend.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID, \"<br>Class:\", CLASS),  \n        color = ~RACE, \n        colors = \"Set1\") %>%\n  \n  layout(title = 'English Score versus Maths Score ',\n         xaxis = list(range = c(0, 100)),\n         yaxis = list(range = c(0, 100)))\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  \n  geom_point(dotsize = 1) +\n  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly\nCode chunk below plots two scatterplots and places them next to each other side-by-side by using subplot() of plotly package.\n\np1 <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),            \n        ggplotly(p2))            \n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly\nTo create a coordinated scatterplots, highlight_key() of plotly package is used.\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\nd <- highlight_key(exam_data)\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends html widgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\nLinked brushing: crosstalk method\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualization-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualization-gganimate-methods",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Animated Data Visualization: gganimate methods",
    "text": "Animated Data Visualization: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customize how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nGetting started\nAdd the following packages in the packages list:\n\ngganimate: An ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\n\n\n\nImporting the data\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       #<<\n  ease_aes('linear')            #<<"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-large-data-interactively",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#visualising-large-data-interactively",
    "title": "Hands-on Exercise 3 - Programming Interactive Data Visualisation with R",
    "section": "Visualising Large Data Interactively",
    "text": "Visualising Large Data Interactively\nFor the purpose of this hands-on exercise, two data sets will be used. They are:\n\nGDP.csv provides GDP, GDP per capita and GDP PPP data for world countries from 2000 to 2020. The data was extracted from World Development Indicators Database of World Bank.\nWorldCountry.csv provides a list of country names and the continent they belong to extracted from Statistics Times.\nWrite a code chunk to import both data sets by using read_csv() of readr package.\n\n\nGDP <- read_csv(\"data/GDP.csv\")\nWorldCountry <- read_csv(\"data/WorldCountry.csv\")\n\n\nData preparation\nBefore programming the data visualization, it is important for us to reshape, wrangle and transform the raw data to meet the data visualization need.\nCode chunk below performs following tasks:\n\nmutate() of dplyr package is used to convert all values in the 202 field into numeric data type.\nselect() of dplyr package is used to extract column 1 to 3 and Values field.\npivot_wider() of tidyr package is used to split the values in Series Name field into columns.\nleft_join() of dplyr package is used to perform a left-join by using Country Code of GDP_selected and ISO-alpha3 Code of WorldCountry tibble data tables as unique identifier.\n\n\nGDP_selected <- GDP %>%\n  mutate(Values = as.numeric(`2020`)) %>%\n  select(1:3, Values) %>%\n  pivot_wider(names_from = `Series Name`,\n              values_from = `Values`) %>%\n  left_join(y=WorldCountry, by = c(\"Country Code\" = \"ISO-alpha3 Code\"))\n\n\n\nIntroducing packed bar method\n\npacked bar is a relatively new data visualization method introduced by Xan Gregg from JMP.\nIt aims to support the need of visualising skewed data over hundreds of categories.\nThe idea is to support the Focus+Context data visualization principle.\nVisit this JMP Blog to learn more about the design principles of packed bar.\n\n\n\nData Preparation\n\nGDP_selected <- GDP %>%\n  mutate(GDP = as.numeric(`2020`)) %>%\n  filter(`Series Name` == \"GDP (current US$)\") %>%\n  select(1:2, GDP) %>%\n  na.omit()\n\n\n\nBuilding a packed bar by using rPackedBar package\nIn the code chunk below, plotly_packed_bar() of rPackedBar package is used to create an interactive packed bar.\n\np = plotly_packed_bar(\n  input_data = GDP_selected,\n  label_column = \"Country Name\",\n  value_column = \"GDP\",\n  number_rows = 10,\n  plot_title = \"Top 10 countries by GDP, 2020\",\n  xaxis_label = \"GDP (US$)\",\n  hover_label = \"GDP\",\n  min_label_width = 0.018,\n  color_bar_color = \"#00aced\",\n  label_color = \"white\")\nplotly::config(p, displayModeBar = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis, Visualizing Uncertainty, Building Funnel Plot with R",
    "section": "",
    "text": "options(repos=c(cran=\"http://cran.rstudio.com\"))\npacman::p_load(ggstatsplot, readxl, performance, parameters, see, FunnelPlotR, plotly, knitr, tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n The Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam_data,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\n\n\n \n\n\n\nSignificant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 <- exam_data %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n <- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-uncertainty",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis, Visualizing Uncertainty, Building Funnel Plot with R",
    "section": "Visualizing Uncertainty",
    "text": "Visualizing Uncertainty\n\nVisualizing the uncertainty of point estimates\n\nA point estimate is a single number, such as a mean.\nUncertainty is expressed as standard error, confidence interval, or credible interval\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below is used to reveal the standard error of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates with interactive error bars\n<insert code chunk>\n\n\n\nVisualizing Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\n\n\n\nVisualizing Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#building-funnel-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#building-funnel-plot",
    "title": "Hands-on Exercise 4 - Visual Statistical Analysis, Visualizing Uncertainty, Building Funnel Plot with R",
    "section": "Building Funnel Plot",
    "text": "Building Funnel Plot\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. Through this exercise, we:\n\nplot funnel plots by using funnelPlotR package,\nplott static funnel plot by using ggplot2 package, and\nplot interactive funnel plot by using both plotly R and ggplot2 packages\n\n\nImporting Data\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\n\n\nFunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nFunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nFunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<\n  xrange = c(0, 6500),  #<<\n  yrange = c(0, 0.05)   #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n+ data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\nFunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\nFunnel Plot for Fair Visual Comparison: ggplot2 methods\nWe aim to enhance the working experience of ggplot2 and customize speciallised data visualization like funnel plot.\n\nComputing the basic derived fields\nWe need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\n\n\n\n\npacman::p_load(ggtern, plotly, corrplot, tidyverse)\n\n\n\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-1",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Overview",
    "text": "Overview\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficients of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this exercise, we plot data for visualizing correlation matrix with R. First, we will create correlation matrix using pairs() of R Graphics. Next, plot corrgram using corrplot package of R. Lastly, create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-1",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nInstall and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(tidyverse, ggstatsplot)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Importing and Preparing the Data Set",
    "text": "Importing and Preparing the Data Set\nImport the data into R by using read_csv() of readr package.\n\nwine <- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Building Correlation Matrix: pairs() method",
    "text": "Building Correlation Matrix: pairs() method\n\nBuilding a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\nDrawing the lower corner\npairs function of R Graphics provided many customization arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, we display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\nIncluding with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Visualising Correlation Matrix: ggcormat()",
    "text": "Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualization technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\n\nThe basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\n# ggstatsplot::ggcorrmat(\n#   data = wine,\n#   cor.vars = 1:11)\n\n\n# ggstatsplot::ggcorrmat(\n#   data = wine,\n#   cor.vars = 1:11,\n#   ggcorrplot.args = list(outline.color = \"black\",\n#                          hc.order = TRUE,\n#                          tl.cex = 10),\n#   title    = \"Correlogram for wine dataset\",\n#   subtitle = \"Four pairs are no significant at p < 0.05\"\n# )\n\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))\n\n\n\nBuilding multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\nTo build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Visualising Correlation Matrix using corrplot Package",
    "text": "Visualising Correlation Matrix using corrplot Package\n\nGetting started with corrplot\nThe code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor <- cor(wine[, 1:11])\n\ncorrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\n\n\nWorking with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. This default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\nWorking with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\nThe default layout of the corrgram can be further customized. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\nWorking with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualization style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe arguments lower and upper are used to define the visualization method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other hand, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\nCombining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\nReorder a corrgram\nMatrix reorder is very important for mining the hidden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\nReordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-2",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Overview",
    "text": "Overview\nHeatmaps visualize data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in a row and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this we plot static and interactive heatmap for visualizing and analyzing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-launching-r-packages-2",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-and-preparing-the-data-set-1",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Importing and Preparing The Data Set",
    "text": "Importing and Preparing The Data Set\n\nImporting the data set\nFor this exercise, we use data from World Happines 2018 report.\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\n\nPreparing the data\n\nrow.names(wh) <- wh$Country\n\n\n\nTransforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make a heatmap.\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#static-heatmap",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Static Heatmap",
    "text": "Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\nheatmap()of R stats package. It draws a simple heatmap.\n\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis).\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types.\n\n\nheatmap() of R Stats\nWe plot a heatmap by using heatmap() of Base Stats.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nNote: By default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we have to use the default as shown in the code chunk below.\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. However, this heatmap is not really informative. The Happiness Score variable have relatively higher values, makes the other variables with small values look all the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalizes the matrix column-wise.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Creating Interactive Heatmap",
    "text": "Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\n\nWorking with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\nUnlike heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\nData transformation\nWhen analyzing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalize and percentilse.\n\nScaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nNormalizing method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalize method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nPercentising method\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\n\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\nClustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\n\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nStatistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\nSeriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we use seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\nWorking with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\nThe finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview-3",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Overview",
    "text": "Overview\nParallel coordinates plot is a data visualization specially designed for visualizing and analyzing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualization technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few (2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nIn this exercise, we will -\n\nplot statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplot interactive parallel coordinates plots by using parcoords package, and\nplot interactive parallel coordinates plots by using parallelPlot package.\n\n\nInstalling and Launching R Packages\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\nData Preparation\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh <- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Plotting Static Parallel Coordinates Plot",
    "text": "Plotting Static Parallel Coordinates Plot\nIn this section, we plot static parallel coordinates plot by using ggparcoord() of GGally package.\n\nPlotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nData argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\nPlotting a parallel coordinates with boxplot\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\nParallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\nRotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\nAdjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 5 - Building Ternary Plot with R, Visualising Correlation Matrices, Building Heatmap for Visualising and Analysing Multivariate Data, Creating Parallel Coordinates Plots with R",
    "section": "Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\nThe basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\n\nRotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nVe can click on a variable of interest, for example Happiness score. The blue colour (default) will change to blues with different intensity based on the colour scheme used.\n\n\nChanging the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\nParallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 01",
    "section": "",
    "text": "Getting started with Tableau\nIn this exercise, we use Tableau’s Superstore data for analysis and visualization\nSee below the dashboard of In-Class Exercise 1 -"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "update.packages(checkBuilt = TRUE, ask = FALSE)\n\nInstalling and loading R packages\nTwo packages will be installed and loaded. They are: tidyverse and ggiraph\n\npacman::p_load(ggiraph, tidyverse)\n\nImporting data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nggplot(data=exam_data, #gives you a blank data frame\n       aes(x = MATHS)) + #aesthetic mapping refers to the data column or field you want to plot\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(dplyr, ggiraph, ggplot2, ggstats, ggstatsplot, ggthemes, ggrepel, gganimate, patchwork, hrbrthemes, plotly, DT, RColorBrewer, gridExtra, extrafont, performance, see, readxl, parameters, gtsummary, crosstalk, ggdist, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#reading-the-dataset",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#reading-the-dataset",
    "title": "In-class Exercise 4",
    "section": "Reading the dataset",
    "text": "Reading the dataset\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#working-with-visual-variable-plot_ly-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#working-with-visual-variable-plot_ly-method",
    "title": "In-class Exercise 4",
    "section": "Working with visual variable: plot_ly() method",
    "text": "Working with visual variable: plot_ly() method\n\nplot_ly(data = exam_data, x = ~ENGLISH, y= ~MATHS, color = ~RACE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-an-interactive-scatter-plot-ggplotly-method",
    "title": "In-class Exercise 4",
    "section": "Creating an interactive scatter plot: ggplotly() method",
    "text": "Creating an interactive scatter plot: ggplotly() method\n\n#interactive plot\n\np <- ggplot (data = exam_data, \n             aes(x = MATHS, y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n#Static plot for comparison\n\nggplot (data = exam_data, \n             aes(x = MATHS, y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#two-sample-mean-test-ggbetweenstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#two-sample-mean-test-ggbetweenstats",
    "title": "In-class Exercise 4",
    "section": "Two-sample mean test: ggbetweenstats()",
    "text": "Two-sample mean test: ggbetweenstats()\n\nggbetweenstats(data = exam_data, x = GENDER, y = MATHS, type = \"p\", messages = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#significant-test-of-correlation-ggscatterstats",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#significant-test-of-correlation-ggscatterstats",
    "title": "In-class Exercise 4",
    "section": "Significant Test of Correlation: ggscatterstats()",
    "text": "Significant Test of Correlation: ggscatterstats()\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-excel-file-readxl-methods",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-excel-file-readxl-methods",
    "title": "In-class Exercise 4",
    "section": "Importing Excel file: readxl methods",
    "text": "Importing Excel file: readxl methods\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \"data\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#multiple-regression-model-using-lm",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#multiple-regression-model-using-lm",
    "title": "In-class Exercise 4",
    "section": "Multiple Regression Model using lm()",
    "text": "Multiple Regression Model using lm()\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-summary-in-a-dataframe-form",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-summary-in-a-dataframe-form",
    "title": "In-class Exercise 4",
    "section": "Model summary in a dataframe form",
    "text": "Model summary in a dataframe form\n\ntbl_regression(model, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,636,783\n-3,150,331, -2,123,236\n<0.001\n    Age_08_04\n-14\n-35, 7.1\n0.2\n    Mfg_Year\n1,315\n1,059, 1,571\n<0.001\n    KM\n-0.02\n-0.03, -0.02\n<0.001\n    Weight\n19\n17, 21\n<0.001\n    Guarantee_Period\n28\n3.8, 52\n0.023\n  \n  \n  \n    \n      1 CI = Confidence Interval"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-checking-for-multi-colinearity",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-checking-for-multi-colinearity",
    "title": "In-class Exercise 4",
    "section": "Model Diagnostic: checking for multi-colinearity",
    "text": "Model Diagnostic: checking for multi-colinearity\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-check-model-for-homogeneity-of-variances",
    "title": "In-class Exercise 4",
    "section": "Model Diagnostic: Check model for homogeneity of variances",
    "text": "Model Diagnostic: Check model for homogeneity of variances\n\ncheck_h <- check_heteroscedasticity(model)\nplot(check_h)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-complete-check",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#model-diagnostic-complete-check",
    "title": "In-class Exercise 4",
    "section": "Model Diagnostic: Complete check",
    "text": "Model Diagnostic: Complete check\n\ncheck_model(model)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-see-methods",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-see-methods",
    "title": "In-class Exercise 4",
    "section": "Visualising Regression Parameters: see methods",
    "text": "Visualising Regression Parameters: see methods\n\nplot(parameters(model))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-ggcoefstats-methods",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising-regression-parameters-ggcoefstats-methods",
    "title": "In-class Exercise 4",
    "section": "Visualising Regression Parameters: ggcoefstats() methods",
    "text": "Visualising Regression Parameters: ggcoefstats() methods\n\nggcoefstats(model, output = \"plot\")\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "In-class Exercise 4",
    "section": "Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "Visualizing the uncertainty of point estimates: ggplot2 methods\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nmy_sum\n\n# A tibble: 4 × 5\n  RACE        n  mean    sd    se\n  <chr>   <int> <dbl> <dbl> <dbl>\n1 Chinese   193  76.5  15.7  1.13\n2 Indian     12  60.7  23.4  7.04\n3 Malay     108  57.4  21.1  2.04\n4 Others      9  69.7  10.7  3.79\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods-1",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods-1",
    "title": "In-class Exercise 4",
    "section": "Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "Visualizing the uncertainty of point estimates: ggplot2 methods\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "pacman::p_load(ggtern, corrplot, ggstatsplot, seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\n\nwine <- read_csv('data/wine_quality.csv')\n\n\n\n\n\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\n#ggcorrmat(data = wine, cor.vars = 1:11)\n\n\n\n\n\n# ggstatsplot::ggcorrmat(\n#   data = wine,\n#   cor.vars = 1:11,\n#   ggcorrplot.args = list(outline.color = \"black\", hc.order = TRUE,tl.cex = 10),\n#   title    = \"Correlogram for wine dataset\",\n#   subtitle = \"Four pairs are no significant at p < 0.05\"\n# )\n\nNote: Tidyverse package can mess with the select function. To prevent this, you can call the dplyr package to run the select function (dplyr::select)\nFor creating a corrplot, one needs first create a correlation matric table\n\nwine.cor <- cor(wine[, 1:11])\n\n\n\n\n\n#|fig-width: 9\n#|fig-height: 9\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-the-data",
    "title": "In-class Exercise 5",
    "section": "Import the data",
    "text": "Import the data\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-data",
    "title": "In-class Exercise 5",
    "section": "Preparing the data",
    "text": "Preparing the data\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-ternary-plot",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-ternary-plot",
    "title": "In-class Exercise 5",
    "section": "Plotting ternary plot",
    "text": "Plotting ternary plot\n\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-the-data",
    "title": "In-class Exercise 5",
    "section": "Importing the data",
    "text": "Importing the data\n\nwh <- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-data-1",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-data-1",
    "title": "In-class Exercise 5",
    "section": "Preparing the data",
    "text": "Preparing the data\nReplace index with country name column\n\nrow.names(wh) <- wh$Country"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#transforming-the-data-frame-into-a-matrix",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#transforming-the-data-frame-into-a-matrix",
    "title": "In-class Exercise 5",
    "section": "Transforming the data frame into a matrix",
    "text": "Transforming the data frame into a matrix\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-the-heatmap",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-the-heatmap",
    "title": "In-class Exercise 5",
    "section": "Plotting the heatmap",
    "text": "Plotting the heatmap\nUsing heatmaply, we plot the heatmap excluding some column values\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. On this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "The datasets, ‘Population of Males by Age Groups and Planning Areas’ and ‘Population of Females by Age Groups and Planning Areas,’ were sourced from Singapore’s Department of Statistics (SingStat) website. Click on this link for more information.\n\n\n\n\n\n\n\n\nAfter downloading the data, the requisite worksheets were cleaned and organized for analysis. All ‘Planning Area’ sections by ‘Age’ were combined. The process was applied to both ‘Population of Males by Age Groups and Planning Areas’ and ‘Population of Females by Age Groups and Planning Areas’ MS Excel worksheets.\n\n\n\n\nFor better analysis in Tableau, it is preferable to have data organized as long and lean rather than short and wide. Hence, the short and wide data structure in MS Excel worksheets were opened in Tableau, and all the five-year age bands were pivoted for long and lean data structure. This process is done individually for ‘Population of Males by Age Groups and Planning Areas’ and ‘Population of Females by Age Groups and Planning Areas’.\nThe MS Excel worksheet is first loaded to Tableau.\n\nNext, all five-year age bands are selected and pivoted to transform the data structure.\n\nUsing ‘View Data’ option, the long and lean data – for both males and females – is downloaded as CSV files.\n\n\nThe column names retained in each MS Excel worksheets post pivoting were ‘Planning Area’, ‘Subzone’, ‘Age’ (for five-year age bands), ‘Gender’ (Male or Female, depending on the data worksheet), and ‘Population’ (representing the corresponding population count)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#union-of-two-datasets",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#union-of-two-datasets",
    "title": "Take Home Exercise 1",
    "section": "2.1. Union of two datasets",
    "text": "2.1. Union of two datasets\nAfter loading the MS Excel worksheets (note: Male and Female population worksheets should be saved in the same MS Excel workbook), we use the ‘New Union’ option in Tableau to combine the ‘Population of Males by Age Groups and Planning Areas’ and ‘Population of Females by Age Groups and Planning Areas’. This gives us a combined long and lean data structure by Planning Area, Subzone, Age Groups, Sex, and Population (actuals)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-new-variables-for-33-panel-charts",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-new-variables-for-33-panel-charts",
    "title": "Take Home Exercise 1",
    "section": "2.2. Creating new variables for 3*3 panel charts",
    "text": "2.2. Creating new variables for 3*3 panel charts\nTo divide the Tableau worksheet into nine panels of 3 by 3 matrix, we created three calculated fields – Index, Column, and Row. The calculated field is created in the working Tableau sheet. Click on the arrow next to the Data field and select Create Calculated Field.\n\nThe formula for these calculated fields are used to derive the logic in the image below.\n Such panelling helps to aesthetically divide nine planning areas in the worksheet and makes the trellis charts both beautiful and insightful."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-new-variables-aggregating-the-female-and-male-population",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-new-variables-aggregating-the-female-and-male-population",
    "title": "Take Home Exercise 1",
    "section": "2.3. Creating new variables aggregating the female and male population",
    "text": "2.3. Creating new variables aggregating the female and male population\nFor the left-side of the trellis chart, we represented the proportion of female population in respective planning areas and on the right-side, we represented the proportion of male population. To do this, we create two conditional calculated fields, one for each female and male."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-region-variable-for-assigning-the-planning-areas",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-region-variable-for-assigning-the-planning-areas",
    "title": "Take Home Exercise 1",
    "section": "2.4. Creating Region variable for assigning the Planning Areas",
    "text": "2.4. Creating Region variable for assigning the Planning Areas\nThe planning areas are geographically distributed into Central Region (including Core Central and Other Central Area), East Region, North-East Region, North Region, and West Region. Based on geographic location, the Planning Areas are assigned their respective Region as follows –\nIF ([Planning Area] = “Bishan” OR [Planning Area] = “Bukit Merah” OR [Planning Area] = “Geylang” OR [Planning Area] = “Kallang” OR [Planning Area] = “Marine Parade” OR [Planning Area] = “Museum” OR [Planning Area] = “Queenstown” OR [Planning Area] = “Simpang” OR [Planning Area] = “Singapore River” OR [Planning Area] = “Southern Islands” OR [Planning Area] = “Straits View” OR [Planning Area] = “Toa Payoh”) THEN “Other C”\nELSEIF ([Planning Area] = “Bukit Timah” OR [Planning Area] = “Downtown Core” OR [Planning Area] = “Marina East” OR [Planning Area] = “Marina South” OR [Planning Area] = “Newton” OR [Planning Area] = “Novena” OR [Planning Area] = “Orchard” OR [Planning Area] = “Outram” OR [Planning Area] = “River Valley” OR [Planning Area] = “Rochor” OR [Planning Area] = “Tanglin”) THEN “Core C”\nELSEIF ([Planning Area] = “Bedok” OR [Planning Area] = “Changi” OR [Planning Area] = “Changi Bay” OR [Planning Area] = “Pasir Ris” OR [Planning Area] = “Paya Lebar” OR [Planning Area] = “Tampines”) THEN “E”\nELSEIF ([Planning Area] = “Central Water Catchment” OR [Planning Area] = “Lim Chu Kang” OR [Planning Area] = “Mandai” OR [Planning Area] = “Sembawang” OR [Planning Area] = “Sungei Kadut” OR [Planning Area] = “Woodlands” OR [Planning Area] = “Yishun”) THEN “N”\nELSEIF ([Planning Area] = “Ang Mo Kio” OR [Planning Area] = “Hougang” OR [Planning Area] = “North-Eastern Islands” OR [Planning Area] = “Punggol” OR [Planning Area] = “Seletar”  OR [Planning Area] = “Sengkang” OR [Planning Area] =  “Serangoon”) THEN “NE”\nELSE “W” END\nCore C - Core Central Region/Central Area, Other C - Other Central Region, N - North Region, E - East Region, NE - North East Region, W - West Region"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-the-trellis-charts",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-the-trellis-charts",
    "title": "Take Home Exercise 1",
    "section": "2.5. Creating the Trellis Charts",
    "text": "2.5. Creating the Trellis Charts\n\nFilter Panel - In the Filter Panel, we first drag the Region Pill and select ‘Core C’ option only. Next we drag the Planning Area pill. Edit the filter criteria as mentioned in the image below to select nine most populous Planning Areas in the Central Area.\n\nColumns and Rows Panel - Drag Column variable (discreet), Females variable (continuous), and Males variable (continuous) in the column panel. Drag Row variable (discreet) and Age variable (discreet) in the row panel.\n\nClick on the arrow of Females pill in the columns panel, and transform the measure into Sum as shown below (repeat the same for the Males pill).\n\nClick on the arrow of SUM(Females) pill in the columns panel, and edit the table calculation as shown below to derive proportions of females across age groups for each area (repeat the same for the SUM(Males) pill).\n\nMarks Panel - In the Marks panel, drag Age Groups to Color, and Planning Area and Index to Details. Next, click on Label in the Marks panel and enable ‘Show Marks Label’ to activate labels. Do this for All, SUM(Females), and SUM(Males)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#enhancing-the-aesthetics",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#enhancing-the-aesthetics",
    "title": "Take Home Exercise 1",
    "section": "2.6. Enhancing the Aesthetics",
    "text": "2.6. Enhancing the Aesthetics\n\nGrouping the five-year age-bands - We grouped the five-year age bands as follows to condense the groupings to five main buckets. In Section 3.2., we cover the purpose and the definition of grouping the age bands.\n\nReversing the axis of the left-side chart - We click on the Female axis in the worksheet and reverse the axis to achieve the trellis chart. See below the image for reversing the axis. Note, this is done only for the left-side chart.\n\nAnnotating the titles for each Planning Area chart - To mark Planning Area as titles in each of the nine charts, we right click on each panel chart, select the Annotate option, and then select Area option. This offers a text box for annotating that can be used to mark the title for each trellis chart in the nine panels.\n\nMiscellaneous Enhancements - We assign a color palette in the Marks Panel to Age pill, edit the axes start and end points for better readability, eliminate extra grid lines and borders from the worksheet, enhance the title, label, and axes fonts for a clean and beautified trellis chart."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-the-final-dashboard",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-the-final-dashboard",
    "title": "Take Home Exercise 1",
    "section": "2.7. Creating the final dashboard",
    "text": "2.7. Creating the final dashboard\n\nThe ‘Size’ of the dashboard is set to ‘Automatic’ from ‘Fixed’. This helps to adjust the dashboard layout to the viewing screen.\nThe trellis panel chart worksheet is dragged to the dashboard from the ‘Sheets’ panel.\nFrom the ‘Objects’ panel, the ‘Text’ object is dragged below the trellis panel chart to include details. The details cover the description of age buckets for the analysis and the data source."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#choosing-the-planning-area",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#choosing-the-planning-area",
    "title": "Take Home Exercise 1",
    "section": "3.1. Choosing the planning area",
    "text": "3.1. Choosing the planning area\nThe Central Area is the core city centre of Singapore. The area dynamic, vibrant, and the hub for global and financial businesses. The Urban Redevelopment Authority (URA) of Singapore suggests that the area is set to grow in terms of businesses and vibrancy by accommodating a wider diversity of uses, job offerings, and business opportunities for the future economy.1\nGiven the outlook provided by URA, it would be interesting to analyze the current population spread in the Central Area. For this purpose, we look at the proportion of females and males by age groups in the nine most populous planning areas in the Central Area - Tanglin, Bukit Timah, Downtown Core, Newton, Novena, Orchard, Outram, River Valley, and Rochor."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-analysis",
    "title": "Take Home Exercise 1",
    "section": "3.2. Data analysis",
    "text": "3.2. Data analysis\nSingapore’s Statistical department provides population figures by sex across five-year age bands starting from age 0 to age 85 and over. However, we combine these five-year age bands into different buckets. These buckets allow us to see the spread of dependent and working adults across the nine areas. See below the detailed note on the age-buckets –\n\nYoung Dependents – Aged 0 to 14, enrolled in schools, and primarily dependent on their parents. Average spread of female young dependents is 14.3% and that of male young dependents is 14.6% across nine planning areas.\nYoung Work(ing) Group – Aged 15 to 29. The younger folks may have some side income while the older folks have completed their degrees and national service and joined the corporate sector. Average spread of female young work group is 15.6% and that of male young dependents is 13.8% across nine planning areas.\nPrime Work(ing) Group – Aged 30 to 49, mostly married individuals that are now primary providers of the family and have the spirit to grow in their career. Average spread of female prime work group is 33.9% and that of male young dependents is 33% across nine planning areas.\nMature Work(ing) Group – Aged 50 to 69, mostly married individuals, have significant job or business experience and are seeking stability. Average spread of female young work group is 26.6% and that of male young dependents is 29.3% across nine planning areas.\nElderly – Aged 70 and above, mostly retired, maybe partially dependent on primary providers. Average spread of female elderly is 9.7% and that of male young dependents is 9.4% across nine planning areas."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#insights",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#insights",
    "title": "Take Home Exercise 1",
    "section": "3.3. Insights",
    "text": "3.3. Insights\nThe female and male distribution across age groups is largely similar across the nine planning groups. Nevertheless, we do see small differences in the distribution for some of the age groups. Few of them to note are –\nKey Finding 01 -\nWhile the average proportion of Young Dependents is around 14% for both females and males across nine regions, this proportion is only 8% and 7%, respectively, in Downtown Core area. This can likely be attributed to higher presence younger workers2, DINK (double income no kids) families, unmarried individuals, and expatriates residing without families in this area.\nKey Finding 02 -\nThe proportion of Prime Work Group was lowest in Bukit Timah - 29% for both males and females. This may be attributed to relatively lower presence of businesses in this area compared to other eight planning areas and high rental property rates.\nKey Finding 03 -\nDowntown Core, Outram, and Rochor had comparatively higher proportion of female and male elderly population residing in these areas – around 12% to 15%. This can be attributed to highest number of residents being employed in these areas, especially from the elderly group.3"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take Home Exercise 2",
    "section": "",
    "text": "The objective of this exercise is to critique the age-sex population pyramid by nine planning areas trellis chart of one of our peers and offer enhancements in R Studio by using visualization analytics and application best practices taught in lecture 1 and lecture 2."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#original-design",
    "title": "Take Home Exercise 2",
    "section": "1. Original Design",
    "text": "1. Original Design\n\n\n\n\n\nThe trellis chart (butterfly bar chart) used for visualization is good for representing the sex distribution by age-groups in different planning areas.\n\n1.1. Clarity:\n\n1.1.1. Non-descriptive graph title:\nThe criteria for selecting the nine planning areas is unclear from the title. Also, the year of population age-sex pyramid analysis is unclear from the title.\n\n\n1.1.2. No age-band grouping:\nGrouping the 5-year age bands into 10-years or any other grouping would make the y-axis clean and more readable for the viewer.\n\n\n1.1.3. Missing title for age-bands on the y-axis:\nThe y-axis has no title that mentions that the axis represents age-bands for the population.\n\n\n1.1.4. No fixed scale:\nX-axis labels are missing, making it difficult for the viewer to know the figures for male and female population. Also, the x-axis scale across nine panels is not fixed. This makes comparison of information across nine planning regions challenging for the viewer.\n\n\n1.1.5. Missing legend:\nThe legend describing the colour of the bars on the left- and the right-side of the trellis chart is missing. The viewer thus has to assume that the pink bars represent female population and the blue bars represent the male population.\n\n\n1.1.6. No data source information:\nIncluding the data source information enhances the credibility of the trellis chart figures.\n\n\n\n1.2. Aesthetics:\n\n1.2.1. Charts in different sheets:\nThe trellis chart for each of the nine regions have been created in nine different sheets and then paneled together in the Tableau dashboard. This results in creation of y-axis nine times, reducing the dashboard white space for expanding the trellis charts.\n\n\n1.2.2. Missing bar labels:\nHaving labels for the bars enhances the readability for the viewer. Hence, including labels can be good practice, especially when there are many bars in the trellis charts.\n\n\n1.2.3. Enhanced age axis:\nCurrently, the labels for the age axis are generic (i.e. they are same as provided by the data source) and not enhanced for aesthetics. Editing the axis labels for better readability can beautify the trellis chart.\n\n\n1.2.4. Non-supportive grid lines:\nAs population labels are missing on the x-axis, the grid lines in the trellis charts are redundant as they provide not supportive information."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#proposed-design",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#proposed-design",
    "title": "Take Home Exercise 2",
    "section": "2. Proposed Design",
    "text": "2. Proposed Design\n\n2.1. The sketch:\nThe sketch is the design for the age-sex population pyramid for one of the chosen nine planning areas. The chart will be replicated and modified for the rest of the other eight planning areas. The sketch details the enhancements to the original chart design.\n\n\n\n2.2. Getting started:\n\n2.2.1. Installing the necessary packages:\nTo start using ggplot2, ggiraph, and tidyverse packages for analysis and visualization, we load the libraries using the pacman package and p_load function in R Studio. We load other packages as well to support formatting of the ggplot.\n\npacman::p_load(dplyr, ggiraph, ggplot2, patchwork, ggthemes, hrbrthemes, ggrepel, RColorBrewer, gridExtra, extrafont, tidyverse)\n\n\nfont_import()\nloadfonts(device = \"win\")\n\n\n\n2.2.2. Importing the data:\nNext, we import the Age-Sex Population Data of Singapore for data manipulation and creating the trellis chart for the nine planning areas.\n\nPopulation_data <- read_csv(\"data/TH02_AgeSexPop.csv\")\n\nRows: 1980 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): Sex, Planning Area, Age Group, Pop_Proportion\ndbl (1): Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n2.3. Data wrangling:\nStep 1 - Combining the age-bands\nWe regroup the data into ten-year age bands from the five-year age bands. We do this to minimize the level of details for the viewer. This helps to create a clean, condensed yet informational chart that is comparatively easier, than the detailed chart, for the viewer to comprehend.\n\nPopulation_data$Age_groups <- with(Population_data, \n                                   dplyr::case_when(`Age Group` %in% c(\"0 - 4\", \"5 - 9\") ~ '0 - 9',\n                                               `Age Group` %in% c(\"10 - 14\", \"15 - 19\") ~ '10 - 19',\n                                               `Age Group` %in% c(\"20 - 24\", \"25 - 29\") ~ '20 - 29',\n                                               `Age Group` %in% c(\"30 - 34\", \"35 - 39\") ~ '30 - 39',\n                                               `Age Group` %in% c(\"40 - 44\", \"45 - 49\") ~ '40 - 49',\n                                               `Age Group` %in% c(\"50 - 54\", \"55 - 59\") ~ '50 - 59',\n                                               `Age Group` %in% c(\"60 - 64\", \"65 - 69\") ~ '60 - 69',\n                                               `Age Group` %in% c(\"70 - 74\", \"75 - 79\") ~ '70 - 79',\n                                               `Age Group` %in% c(\"80 - 84\", \"85 & Over\") ~ '80+'))\n\nStep 2 - Selecting the planning areas\nAs per the problem statement, we need to select nine planning areas of Singapore and present the age-sex population pyramid for the user. For this exercise, we select the top nine most populous planning areas of Singapore in 2022.\nStep 3 - Creating a data subset\nBased on the chosen nine planning areas, we create a subset from the main dataset. Such a subset makes it easy to further wrangle and visualize the data using ggplot2 and tidyverse.\n\ndata_PA <- Population_data %>%\n  group_by(`Planning Area`) %>%\n  summarise(sum_pop = sum(Population), .groups = 'drop') %>%\n  arrange(sum_pop,.by_group = TRUE) %>%\n  top_n(9)\n\nSelecting by sum_pop\n\ndata_PA\n\n# A tibble: 9 × 2\n  `Planning Area` sum_pop\n  <chr>             <dbl>\n1 Choa Chu Kang    174430\n2 Ang Mo Kio       174920\n3 Yishun           202060\n4 Sengkang         206730\n5 Hougang          222450\n6 Woodlands        250270\n7 Tampines         261300\n8 Jurong West      272810\n9 Bedok            289850\n\n\n\ndata_top9 <- Population_data %>% filter(`Planning Area` %in% c(\"Choa Chu Kang\", \"Ang Mo Kio\", \"Yishun\", \"Sengkang\", \"Hougang\", \"Woodlands\", \"Tampines\", \"Jurong West\",\"Bedok\"))\n\nstr(data_top9)\n\nspc_tbl_ [324 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sex           : chr [1:324] \"Female\" \"Female\" \"Female\" \"Female\" ...\n $ Planning Area : chr [1:324] \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" \"Ang Mo Kio\" ...\n $ Age Group     : chr [1:324] \"0 - 4\" \"5 - 9\" \"10 - 14\" \"15 - 19\" ...\n $ Population    : num [1:324] 3310 3790 4100 4600 5180 5810 6450 6890 7100 6670 ...\n $ Pop_Proportion: chr [1:324] \"3.65%\" \"4.18%\" \"4.52%\" \"5.07%\" ...\n $ Age_groups    : chr [1:324] \"0 - 9\" \"0 - 9\" \"10 - 19\" \"10 - 19\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sex = col_character(),\n  ..   `Planning Area` = col_character(),\n  ..   `Age Group` = col_character(),\n  ..   Population = col_double(),\n  ..   Pop_Proportion = col_character()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\n\n2.4. Final outcome:\nWe use ggplot2 attributes to visualize the data and modify them to meet our sketch design. This helps us to create enhanced version of the initial design.\n\ndata_top9 <- data_top9 %>% mutate(tooltip_text = paste0(\"Population actuals \", data_top9$Population, \"\\n\", \"Population Proportion \", data_top9$Pop_Proportion))\n\npp <- ggplot(data = data_top9, aes(x = Age_groups, y = Population, fill = Sex, )) +\n  \n  geom_bar(data = data_top9 %>% filter(Sex == \"Male\"),\n           stat = \"identity\", position = \"identity\") +\n\n#, aes(tooltip = tooltip_text, data_id = Age_groups)) \n                            \n  \n  geom_bar(data = data_top9 %>% filter(Sex == \"Female\"),\n           stat = \"identity\",\n           position = \"identity\",\n           mapping = aes(y = -(Population))) +\n  \n  \n  labs (x = \"Age Group\", y = \"Population in 000s\",  title = str_wrap(\"Age-Sex Pyramid of the 9 most populous planning areas in Singapore, June 2022\", width = 90), caption = \"Source: Department of Statistics, Singapore (SingStat)\") + \n\n  scale_y_continuous(breaks = seq(-15000,15000,3000), labels = c(\"15\", \"12\", \"09\", \"06\", \"03\", \"0\", \"03\", \"06\", \"09\", \"12\", \"15\"))+\n  \n  scale_fill_manual(values = c(\"coral3\", \"darkslateblue\"))+\n\n  coord_flip() +\n\n  theme_minimal () +\n\n  theme(text = element_text(family = \"Georgia\"),\n    \n        plot.margin = margin(t=1, r=1, b=1, l=1),\n        plot.title = element_text(size = 10, face = 'bold', hjust = 0.5),\n        plot.caption = element_text(hjust = 0, face = 'italic'),\n        plot.caption.position = 'plot',\n        \n        panel.grid.major.x = element_line(colour = 'grey', linewidth = 0.3, linetype = \"dashed\"),\n        panel.grid.major.y = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank(),\n        \n        axis.line = element_line(color = 'grey'),\n        axis.title = element_text(size = 8),\n        axis.title.y = element_text(angle = 0, vjust = 1.03),\n        axis.text = element_text(size = 6),\n        axis.ticks.y = element_line(color = 'grey'),\n        axis.ticks.x = element_line('grey'),\n        \n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6)) +\n  \n  # creating a facet wrap for each region\n  facet_wrap(~`Planning Area`, ncol = 3) \n\npp\n\n\n\n#pp2 <- girafe(ggobj = pp)\n#if(interactive()) print(pp2)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-learning",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-learning",
    "title": "Take Home Exercise 2",
    "section": "3. The learning",
    "text": "3. The learning\nEvaluating my peer’s visualization task, helped me learn by putting myself in the viewer’s shoes. Small design enhancements can improve the clarity and the beauty of the charts and make the chart more informative. This exercise also helped me strengthen my skills in R by using the packages such as ggplot2 and tidyverse. Learning these packages is imperative for me as these packages can help me become an efficient and an effective data analyzer and visualizer."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take home exercise 3",
    "section": "",
    "text": "For the purpose of this study, we focus on the resale of 3-ROOM, 4-ROOM and 5-ROOM types flats in Singapore. While we do explore the overall data from 2017, we mainly focus on deep diving into 2022 to gain some insights."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#section",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#section",
    "title": "Take home exercise 3",
    "section": "",
    "text": "About the data\nThe data is covers details of different types of houses sold in Singapore from January 2017 to February 2023. The data is sourced from data.gov.sg.\nThe dataset contains the following fields:\n\n\n\n\n\n\n\n\nField name\nField type\nDescription\n\n\n\n\nmonth\ndate (yyyy-mm)\nThe year and month in which the property resale is recorded\n\n\ntown\ncharacter\nThe planning area in which the property sale is recorded\n\n\nflat_type\ncharacter\nThe type of flat that is sold\n\n\nblock\nnumeric\nThe block number of the property sold\n\n\nstorey_range\ncategorical\nCaptures the storey in range of the property sold\n\n\nfloor_area_sqm\nnumeric\nThe floor size of the property sold in square meters\n\n\nflat_model\ncharacter\nThe model of the flat sold\n\n\nlease_commence_date\nnumeric (yyyy)\nThe year in which the lease of the property commenced\n\n\nremaining_lease\ncharacter (years, months)\nThe time remaining for expiration of the property lease\n\n\nresale_price\nnumeric\nThe price at which the property is sold"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-the-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-the-packages",
    "title": "Take home exercise 3",
    "section": "Installing the packages",
    "text": "Installing the packages\nWe install the required R packages to perform the analysis.\n\npacman::p_load(ggstatsplot, readxl, performance, parameters, see, FunnelPlotR, plotly, knitr, crosstalk, DT, ggdist, gganimate, ggpubr, hrbrthemes, ggridges, ggiraph, viridis, patchwork, scales, treemap, testthat, Hmisc, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-the-data",
    "title": "Take home exercise 3",
    "section": "Importing the data",
    "text": "Importing the data\n\nresale <- read_csv(\"data/resale_flat prices.csv\")\n\nRows: 129909 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling-and-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling-and-preparation",
    "title": "Take home exercise 3",
    "section": "Data Wrangling and Preparation",
    "text": "Data Wrangling and Preparation\n\nPreparing the data\nFor the purpose of our analysis, we need to wrangle the data - create new variables, split fields to get more meaningful insights, and convert variables to the right datatype. Additionally, for overall analysis, we limit our dataset to 3-room, 4-room, and 5-room flat types from 2017 to 2022. This will help us compare year-on-year.\nCreating new variables age, price per square meter (psm), and price in thousands (kprice).\n\nresale <- resale %>%\n  mutate(psm = round(resale_price / floor_area_sqm)) %>% \n  mutate(kprice = round(resale_price / 1000)) %>% \n  mutate(age = round(2022 - lease_commence_date))\n\nSeparating the month column (yyyy-mm) into year (yyyy) and month (mm).\n\nresale <- resale %>%\n  separate(month, c(\"year\", \"month\"), sep = \"-\")\n\nConverting the string variables to integer variables.\n\nresale$year <- strtoi(resale$year)\nresale$month <- strtoi(resale$month)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-overall-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploring-the-overall-data",
    "title": "Take home exercise 3",
    "section": "Exploring the overall data",
    "text": "Exploring the overall data\n\nRidgeline plot\nA Ridgeline plot (sometimes called Joyplot) shows the distribution of a numeric value for several groups.\nFrom the plot below, we see that the resale price distribution over time for planning areas such as Toa Payoh, Bukit Timah, Kallang, Central Area, and Queenstown is wider compared to the other areas. This means the resale price range for properties here is broad.\nWhile the resale prices years over the years, the distribution for all the areas remain somewhat consistent.\n\n\nCode\nggplot(data = resale, aes(x = kprice, y = town, fill = after_stat(x))) +\n  \n  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +\n  \n  theme_classic2() +\n    theme(\n      plot.title = element_text(family = \"Georgia\", face = \"bold\", size = 16),\n      legend.position=\"none\",\n      axis.title.x = element_text(family = \"Georgia\", size = 12, hjust = 1),\n      axis.title.y = element_text(family = \"Georgia\", size = 12, angle = 360),\n      axis.text = element_text(family = \"Georgia\", size = 9)\n      ) +\n  \n  scale_fill_viridis(name = \"resale_prices\", option = \"F\") +\n  \n  labs(title = 'Resale Prices by Planning Area: {frame_time}') +\n  \n  transition_time(resale$year) +\n\n  ease_aes('linear')\n\n\nPicking joint bandwidth of 35\n\n\n\n\n\n\n\nBoxplot\nWe see the price range for all three type of flats (3-room, 4-room, and 5-room) have increased over the years from 2017 to 2022. Correspondingly, the median prices of each of the flat types have also increased over the years.\n\n\nCode\nggplot(data = resale, aes(x = flat_type, y = kprice, fill = flat_type)) +\n  \n  geom_boxplot(mapping = NULL) +\n  \n  theme_classic2() +\n    theme(\n      plot.title = element_text(family = \"Georgia\", face = \"bold\", size = 18),\n      legend.position=\"none\",\n      axis.title.x = element_text(family = \"Georgia\", size = 12, hjust = 1),\n      axis.title.y = element_text(family = \"Georgia\", size = 12, angle = 360),\n      axis.text = element_text(family = \"Georgia\", size = 9)\n      ) +\n  \n  scale_fill_viridis(option = \"F\", discrete = TRUE) +\n\n  labs(title = \"Resale prices in 000s by flat-type: {frame_time}\") +\n  \n  transition_time(resale$year) +\n   \n  ease_aes('linear')"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#deep-dive-2022",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#deep-dive-2022",
    "title": "Take home exercise 3",
    "section": "Deep Dive: 2022",
    "text": "Deep Dive: 2022\nWe now limit our analysis to 2022. This helps us to draw better insights about the 3-room, 4-room, and 5-room flat type sale trend in Singapore.\nFiltering by room-type and year.\n\nresale_2022 <- resale %>%\n  filter(year == 2022, flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n\n\nStudying the data\n\nData Summary\nFrom the table below, we see over 24,000 property transactions were recorded in 2022 for 3-room, 4-room, and 5-room flats in Singapore.\n\nmy_sum <- summary(resale_2022) \nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n      \n         year \n        month \n        town \n     flat_type \n       block \n    street_name \n    storey_range \n    floor_area_sqm \n     flat_model \n    lease_commence_date \n    remaining_lease \n     resale_price \n         psm \n        kprice \n         age \n  \n \n\n  \n     \n    Min.   :2022 \n    Min.   : 1.000 \n    Length:24372 \n    Length:24372 \n    Length:24372 \n    Length:24372 \n    Length:24372 \n    Min.   : 51.00 \n    Length:24372 \n    Min.   :1967 \n    Length:24372 \n    Min.   : 200000 \n    Min.   : 3333 \n    Min.   : 200.0 \n    Min.   : 3.00 \n  \n  \n     \n    1st Qu.:2022 \n    1st Qu.: 3.000 \n    Class :character \n    Class :character \n    Class :character \n    Class :character \n    Class :character \n    1st Qu.: 81.00 \n    Class :character \n    1st Qu.:1985 \n    Class :character \n    1st Qu.: 428000 \n    1st Qu.: 4838 \n    1st Qu.: 428.0 \n    1st Qu.: 8.00 \n  \n  \n     \n    Median :2022 \n    Median : 5.000 \n    Mode  :character \n    Mode  :character \n    Mode  :character \n    Mode  :character \n    Mode  :character \n    Median : 93.00 \n    Mode  :character \n    Median :1998 \n    Mode  :character \n    Median : 515000 \n    Median : 5368 \n    Median : 515.0 \n    Median :24.00 \n  \n  \n     \n    Mean   :2022 \n    Mean   : 6.047 \n    NA \n    NA \n    NA \n    NA \n    NA \n    Mean   : 94.08 \n    NA \n    Mean   :1997 \n    NA \n    Mean   : 536394 \n    Mean   : 5736 \n    Mean   : 536.4 \n    Mean   :24.54 \n  \n  \n     \n    3rd Qu.:2022 \n    3rd Qu.:10.000 \n    NA \n    NA \n    NA \n    NA \n    NA \n    3rd Qu.:110.00 \n    NA \n    3rd Qu.:2014 \n    NA \n    3rd Qu.: 610000 \n    3rd Qu.: 6176 \n    3rd Qu.: 610.0 \n    3rd Qu.:37.00 \n  \n  \n     \n    Max.   :2022 \n    Max.   :12.000 \n    NA \n    NA \n    NA \n    NA \n    NA \n    Max.   :159.00 \n    NA \n    Max.   :2019 \n    NA \n    Max.   :1418000 \n    Max.   :14731 \n    Max.   :1418.0 \n    Max.   :55.00 \n  \n\n\n\n\n\n\n\nHistogram\nWe analyze the distribution and the outliers in the dataset through histograms. We see that resale price in thousands and price per square unit have a right skew.\n\nset.seed(1234)\n\ng_price <- gghistostats(\n  data = resale_2022,\n  x = kprice,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"resale prices in 000s\"\n          ) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      legend.position=\"none\"\n      )\n\ng_psm <- gghistostats(\n  data = resale_2022,\n  x = psm,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"price per sqm\"\n) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      legend.position=\"none\"\n      )\n\ng_farea <- gghistostats(\n  data = resale_2022,\n  x = floor_area_sqm,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"floor area (sqm)\"\n) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      legend.position=\"none\"\n      )\n\ng_age <- gghistostats(\n  data = resale_2022,\n  x = age,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"property age\"\n) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      legend.position=\"none\"\n      )\n\nggarrange(g_price, g_psm, g_farea, g_age, ncol = 2, nrow = 2)\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\nWarning in grid.Call(C_stringMetric, as.graphicsAnnot(x$label)): font family\n'Georgia' not found in PostScript font database\n\n\n\n\n\n\n\nExcluding the outliers\nThus, we exclude the outliers using interquartile range for both resale price in thousands and price per square meter.\n\nIQR_price = IQR(resale_2022$kprice)\nIQR_psm = IQR(resale_2022$psm)\n\nprice_upper = quantile(resale_2022$kprice, probs = 0.75)+1.5*IQR_price\npsm_upper = quantile(resale_2022$psm, probs = 0.75)+1.5*IQR_psm\n\nWe then filter out the dataset and focus on this clean data for property sales in 2022.\n\nresale_filter <- resale_2022 %>%\n  filter((resale_2022$kprice <= price_upper) & \n           (resale_2022$psm <= psm_upper))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis",
    "title": "Take home exercise 3",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\nHistogram after excluding the outliers\nWe see the distribution for resale price in thousands and price per square meter somewhat improve after excluding the outliers using interquartile range (IQR).\n\n\nCode\nm_price = mean(resale_filter$kprice)\nstd_price = sd(resale_filter$kprice)\n\ndist_price <- ggplot(data = resale_filter, aes(kprice)) +\n  geom_histogram(aes(y=after_stat(density)), fill = \"deeppink4\", color = \"black\") + \n  \n  stat_function(fun = dnorm, args = list(mean = m_price, sd = std_price), col=\"darkslategray\", size = .8) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family =\"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      axis.text.y = element_blank(),\n      axis.title.y = element_blank(),\n      axis.ticks.y = element_blank(),\n      axis.line.y = element_blank(),\n      ) +\n  \n  labs(title = 'Distribution of resale price in 000s')\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\nCode\nm_psm = mean(resale_filter$psm)\nstd_psm = sd(resale_filter$psm)\n\ndist_psm <- ggplot(data = resale_filter, aes(psm)) +\n  geom_histogram(aes(y=after_stat(density)), fill = \"deeppink4\", color = \"black\") + \n  \n  stat_function(fun = dnorm, args = list(mean = m_psm, sd = std_psm), col=\"darkslategray\", size = .8) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family =\"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      axis.text.y = element_blank(),\n      axis.title.y = element_blank(),\n      axis.ticks.y = element_blank(),\n      axis.line.y = element_blank()\n      ) +\n  \n  labs(title = 'Distribution of resale price in 000s')\n\n\n\n\nCode\ndist_price + dist_psm\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\nCorrelation Analysis\nAs anticipated, the floor_area shows a strong positive correlation with resale property price.\n\n\nCode\nggscatterstats(\n  data = resale_filter,\n  x = floor_area_sqm,\n  y = kprice,\n  marginal = FALSE,\n  ) +\n\n  theme_classic2() +\n    theme(\n      text = element_text(family =\"Georgia\"),\n      plot.title = element_text(face = \"bold\")\n      ) +\n    \n    labs(title = 'Correlation of resale price (in 000s) and floor area (sqm)', x = \"Floor Area\", y = \"Resale Price in 000s\")\n\n\n\n\n\nBelow we see a quick snapshot of the final dataset we are going to be working with in the further analysis.\n\nmy_des <- describe(resale_filter, num.desc=c(\"mean\",\"median\",\"var\",\"sd\",\"valid.n\"), xname = NA, horizontal=FALSE) %>% html()\n\nWarning in png(file, width = 1 + k * w, height = h): 'width=10, height=13' are\nunlikely values in pixels\n\nmy_des\n\n\n\n\n\n\nresale_filter Descriptives\nresale_filter  15  Variables   22367  Observations\n\nyear\n\n \n nmissingdistinctInfoMeanGmd\n 2236701020220\n \n\n Value       2022\n Frequency  22367\n Proportion     1\n \n\n\nmonth\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 183004067100.996.034.151 1 1 3 5101212\n \n\nlowest :  1  2  3  4  5 ,  highest:  6  7 10 11 12\n Value          1     2     3     4     5     6     7    10    11    12\n Frequency   2100  1586  1895  1906  1806  1754  1963  1619  1773  1898\n Proportion 0.115 0.087 0.104 0.104 0.099 0.096 0.107 0.088 0.097 0.104\n \n\n\ntown\n\n \n nmissingdistinct\n 22367026\n \n\n\n \n lowest :ANG MO KIO BEDOK      BISHAN     BUKIT BATOKBUKIT MERAH\n highest:SERANGOON  TAMPINES   TOA PAYOH  WOODLANDS  YISHUN     \n \n\n\nflat_type\n\n \n nmissingdistinct\n 2236703\n \n\n Value      3 ROOM 4 ROOM 5 ROOM\n Frequency    5948  10235   6184\n Proportion  0.266  0.458  0.276\n \n\n\nblock\n\n \n nmissingdistinct\n 2236702389\n \n\nlowest : 1    10   100  101  101A ,  highest: 989A 989C 989D 99   9A  \n\nstreet_name\n\n \n nmissingdistinct\n 223670540\n \n\n\n \n lowest :ADMIRALTY DR  ADMIRALTY LINKAH HOOD RD    ALJUNIED CRES ALJUNIED RD   \n highest:YUNG AN RD    YUNG HO RD    YUNG KUANG RD YUNG LOH RD   YUNG SHENG RD \n \n\n\nstorey_range\n\n \n nmissingdistinct\n 22367013\n \n\nlowest : 01 TO 03 04 TO 06 07 TO 09 10 TO 12 13 TO 15 ,  highest: 25 TO 27 28 TO 30 31 TO 33 34 TO 36 37 TO 39\n Value      01 TO 03 04 TO 06 07 TO 09 10 TO 12 13 TO 15 16 TO 18 19 TO 21 22 TO 24\n Frequency      4044     5289     4904     4283     2193      974      327      192\n Proportion    0.181    0.236    0.219    0.191    0.098    0.044    0.015    0.009\n                                                        \n Value      25 TO 27 28 TO 30 31 TO 33 34 TO 36 37 TO 39\n Frequency       105       26       19        7        4\n Proportion    0.005    0.001    0.001    0.000    0.000\n \n\n\nfloor_area_sqm\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 2236701000.99894.1522.15 65 67 76 93110121123\n \n\nlowest :  51  52  53  54  55 ,  highest: 149 150 152 155 157\n\nflat_model\n\n \n nmissingdistinct\n 22367012\n \n\n\n \n lowest :3Gen               Adjoined flat      DBSS               Improved           Improved-Maisonette\n highest:Model A2           New Generation     Premium Apartment  Simplified         Standard           \n \n\n\nlease_commence_date\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 223670530.999199616.951975197819841996201320172018\n \n\nlowest : 1967 1968 1969 1970 1971 ,  highest: 2015 2016 2017 2018 2019\n\nremaining_lease\n\n \n nmissingdistinct\n 223670630\n \n\n\n \n lowest :43 years 01 month 43 years 02 months43 years 03 months43 years 04 months43 years 05 months\n highest:95 years 04 months95 years 05 months95 years 06 months95 years 07 months95 years 08 months\n \n\n\nresale_price\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 22367013371507804137936326000350000420000500000580000675000730000\n \n\nlowest : 200000 228888 230000 238000 240000 ,  highest: 878000 878888 880000 881888 882000\n\npsm\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 223670330815422944.84286446347985269592466107065\n \n\nlowest : 3333 3344 3347 3348 3368 ,  highest: 8167 8169 8174 8178 8182\n\nkprice\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 2236706051507.8137.9326350420500580675730\n \n\nlowest : 200 229 230 238 240 ,  highest: 875 878 879 880 882\n\nage\n\n \n nmissingdistinctInfoMeanGmd.05.10.25.50.75.90.95\n 223670530.99925.6916.95 4 5 926384447\n \n\nlowest :  3  4  5  6  7 ,  highest: 51 52 53 54 55\n\n\n\n\n\nViolin Plots\nWe see the resale price distribution by flat_type (3-room, 4-room, and 5-room) using a violin plot. As expected, the median resale prices of 3-room flat type is lower than that of 4-room and 5-room. However, based on the shape of the data, we see that the resale prices of the smaller flats are more concentrated around the median than the bigger sized flats.\nFor price per square meter, the distribution shape for 3-room, 4-room, and 5-room is more or less similar. The price per square meter for all three room types is mostly around the median.\n\nViolin Plot - Resale PriceViolin Plot - PSM\n\n\n\n\nCode\n### Violin Plot for resale price in 000s ###\n\nviolin_kprice <- ggbetweenstats(\n  data = resale_filter,\n  x = flat_type, \n  y = kprice,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n) +\n  \n    theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      \n      plot.title = element_text(face = \"bold\"),\n      \n      legend.position=\"none\",\n      ) +\n  \n  labs(title = 'Resale Price in 000s by Flat Type - 2022', x = \"Planning Area\", y = \"Resale Price\")\n\nviolin_kprice\n\n\n\n\n\n\n\n\n\nCode\n### Violin Plot for resale psm in 000s ###\n\nviolin_psm <- ggbetweenstats(\n  data = resale_filter,\n  x = flat_type, \n  y = psm,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n) +\n\n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      \n      plot.title = element_text(face = \"bold\"),\n      \n      legend.position=\"none\",\n      ) +\n  \n  labs(title = 'Price per Sqaure Meter by Flat Type - 2022', x = \"Planning Area\", y = \"PSM\")\n\nviolin_psm\n\n\n\n\n\n\n\n\n\n\nBoxplot\nNext, we study the box and whiskers plot of 3-room, 4-room, and 5-room flat types across the planning regions.\nWe see that areas such as Jurong West and Tampines have the widest price band for 5-room type flats, especially towards the upper-side of the price. In Marine Parade, the 5-room flat types were significantly higher priced than 3-room and 4-room type flats. The opposite was true for areas such as Sembawang.\n\n\nCode\np <- ggplot(data = resale_filter, mapping = aes(x = town, y = kprice)) +\n  \n  geom_boxplot(aes(fill = as.factor(flat_type))) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\", size = 16),\n  \n      axis.text.x = element_text(angle = 90),\n\n      ) +\n  \n  scale_fill_viridis(name = \"resale_prices\", option = \"F\", discrete = TRUE) +\n  \n  labs(title = 'Resale prices in 000s by Flat Type and Planning Area - 2022', x = \"Planning Area\", y = \"Resale price\", fill = \"flat_type\")\n\nggplotly(p)\n\n\n\n\n\n\n\n\nProportions Charts\nFrom the donut chart, we see that the resale of 4-room properties accounted for the highest share among the three, while sale of number of 3-room and 5-room properties were similar.\nFrom the grouped bar charts, we see that the number of 3-room type property sold is higher than the other from planning areas such as Ang Mio Ko, Bedok, and Queenstown; this is contrast to higher number of 4-room and 5-room type properties sold in areas such as Punggol, Sembawang, Senkang, etc.\n\nFlat type proportion overallFlat type proportion by planning areas\n\n\n\n\nCode\nft_only <- resale_filter %>%\n  group_by(flat_type) %>%\n  summarize(ft_count = n())%>%\n  mutate(ft_pct = percent(ft_count/sum(ft_count)))\n\nggplot(data = ft_only, aes(x = 2, y=ft_count, fill = flat_type)) +\n  geom_bar(stat = \"identity\") +\n  coord_polar(theta = \"y\", start = 0) +\n  xlim(c(0.5, 2.5)) +\n  \n  geom_text(color = \"grey\", size = 4, aes(y = ft_count/3 + c(0, cumsum(ft_count)[-length(ft_count)]), label = ft_pct)) +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      \n      axis.line.x = element_blank(),\n      axis.line.y = element_blank(),\n      axis.ticks = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank(),\n    \n      legend.key.size = unit(5, \"mm\"),\n      legend.position = \"bottom\"\n      \n      ) +\n  \n  scale_fill_viridis(option = \"F\", discrete = TRUE) +\n  \n  labs(title = 'Resale of Flats by Type and Planning Area - 2022', x = \"Planning Area\", y = \"Flat type\", fill = \"Flat type\")\n\n\n\n\n\n\n\n\n\nCode\np <- ggplot(data = resale_filter, aes(x = town, fill=flat_type)) +\n  \n  geom_bar(position = \"dodge\") +\n  \n  theme_classic2() +\n    theme(\n      text = element_text(family = \"Georgia\"),\n      plot.title = element_text(face = \"bold\"),\n      \n      axis.text.x = element_text(angle = 90),\n    \n      legend.key.size = unit(5, \"mm\"),\n      legend.position = \"bottom\"\n      \n      ) +\n  \n  scale_fill_viridis(option = \"F\", discrete = TRUE) +\n  \n  labs(title = 'Resale of Flats by Type and Planning Area - 2022', x = \"Planning Area\", y = \"Flat type\", fill = \"Flat type\")\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nTreemap\nThrough the treemap, we see on overall glimpse of flat types by prices per square meter and resale prices in 000s across all planning areas.\n\ntreemap (resale_filter,\n              index= c(\"flat_type\", \"town\"),\n              vSize= \"psm\",\n              vColor = \"kprice\",\n              type= \"manual\",\n              palette = inferno(5),\n              force.print.labels = F,\n              border.col = c(\"black\", \"white\"),\n              border.lwds = c(3,2),\n              title= \"Properties for resale\",\n              title.legend = \"Median Resale Price in 000s\"\n              )"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#references",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#references",
    "title": "Take home exercise 3",
    "section": "References",
    "text": "References\n\nRidgeline Plot, From Data to Viz, accessed 15 February 2023\nJoel Carron, Violin Plots 101: Visualizing Distribution and Probability Density, Mode, 13 December 2021\nSimon Foo, Analysis of Singapore’s Private Housing Property Market Prices (July 2017 to 2022), RPubs, 21 July 2022\nKenneth Low, Analysis of property market in Singapore, RPubs, accessed 15 February 2023\nWang Wenyi, An analysis of Singapore property resale market price based on transaction from 2017 to 2019, RPubs, 17 July 2020\nIsabelle Liew, HDB resale prices rise 2.3% in Q4, slowest increase in 2022, The Straits Times, 01 February 2023"
  }
]